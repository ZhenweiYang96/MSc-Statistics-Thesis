?large
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
library(tidyverse)
library(lba)
library(caret)
library(cvms)
library(tfruns)
library(ggplot2)
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
library(tidyverse)
######################################################################################
############# LBA-NN Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
# library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv")
test <- read.csv("Data/testdata_1.csv")
test_x <- evm.test(y ~ P, newdata = test, trainingset = train)
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train)
######################################################################################
############# LBA-NN Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
# library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv")
test <- read.csv("Data/testdata_1.csv")
test_x <- evm.test(y ~ P, newdata = test, trainingset = train)
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train)
#################################### Set LBA-NN
# build the model
set_random_seed(10)
lbann.model <- lbann(y ~ P, data = train, num.layer = 8, epochs = 50,
activation.1 = "relu", activation.2 = "softmax",
val_split.ratio = 0, lr = 0.01, K =3)
#################################### Set LBA-NN
# build the model
set_random_seed(10)
lbann.model <- lbann(y ~ P, data = train, num.neurons = 8, epochs = 50,
activation.1 = "relu", activation.2 = "softmax",
val_split.ratio = 0, lr = 0.01, K =3)
#################################### qualitative evaluation
# Importance plot
lbann.model$importance.plot
ggsave("Output/3_importance_plot_example_1.png")
# LBA-NN-K-means
lbann.model$biplot
ggsave("Output/4_biplot_example_1.png")
####################################  quantitative evaluation
## loss
lbann.model$model %>% keras::evaluate(test_x, test_y) # loss = 0.07
## accuracy + precision + recall + specificity + f1-score
y_pred.lbann <- predict(lbann.model$model, x = test_x)
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]})
confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # accuracy = 0.75
confusion.summary <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
class(confusion.summary)
confusion.summary
save(confusion.summary, "Output/summary.txt")
save(confusion.summary)
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
tocsv <- data.frame(cbind(t(cm$overall),t(cm$byClass)))
as.matrix(cm, what = "classes")
var <- c("Balanced Accuracy","Pos Pred Value","Recall", "Specificity", "F1")
cm.sum <- as.matrix(cm, what = "classes")[var,]
cm.sum
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
var <- c("Balanced Accuracy","Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
var <- c("Balanced Accuracy","Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm.sum <- data.frame(LBANN = apply(cm, 1, mean))
colnames(cm.sum) <- c("accuracy", "precision", "recall", "specificity", "f1-score")
row.names(cm.sum) <- c("accuracy", "precision", "recall", "specificity", "f1-score")
cm.sum
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
acc
acc <- as.matrix(cm,what="overall")
acc
acc <- as.matrix(cm,what="overall")[1]
acc
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm.sum <- data.frame(LBANN = c(acc, apply(cm, 1, mean)))
row.names(cm.sum) <- c("accuracy", "precision", "recall", "specificity", "f1-score")
cm.sum
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm.sum <- data.frame(LBANN = round(c(acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("accuracy", "precision", "recall", "specificity", "f1-score")
cm.sum
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x)
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]})
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm.sum <- data.frame(LBANN = round(c(acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/5_1_summary_prediction.csv")
eval <- cvms::evaluate(
data = data.frame(predict = as.character(y_pred.lbann), true = as.character(test$y)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/5a_confusion_matrix_lbann.png")
plot_confusion_matrix(eval)
dev.off()
######################################################################################
############# LBA Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(lba)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv")
test <- read.csv("Data/testdata_1.csv")
test_x <- evm.test(y ~ P, newdata = test, trainingset = train)
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train)
#################################### LBA
set.seed(1)
contable <- table(train$P, train$y)
######################################################################################
############# LBA-NN Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv")
test <- read.csv("Data/testdata_1.csv")
test_x <- evm.test(y ~ P, newdata = test, trainingset = train)
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train)
#################################### Set LBA-NN
# build the model
set_random_seed(10)
lbann.model <- lbann(y ~ P, data = train, num.neurons = 8, epochs = 50,
activation.1 = "relu", activation.2 = "softmax",
val_split.ratio = 0, lr = 0.01, K =3)
#################################### qualitative evaluation
# Importance plot
lbann.model$importance.plot
ggsave("Output/fig3_importance_plot_example_1.png")
# LBA-NN-K-means
lbann.model$biplot
ggsave("Output/fig4_biplot_example_1.png")
####################################  quantitative evaluation
## mean sqaure error
lbann.model$model %>% keras::evaluate(test_x, test_y) # mse = 0.07
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x)
####################################  quantitative evaluation
## mean sqaure error
lbann.model$model %>% keras::evaluate(test_x, test_y)[1] # mse = 0.07
####################################  quantitative evaluation
## mean sqaure error
lbann.model$model %>% keras::evaluate(test_x, test_y) # mse = 0.07
lbann.model$model %>% keras::evaluate(test_x, test_y)[1,]
class(lbann.model$model %>% keras::evaluate(test_x, test_y))
lbann.model$model %>% keras::evaluate(test_x, test_y)
mse <- lbann.model$model %>% keras::evaluate(test_x, test_y)
mse
mse[1]
####################################  quantitative evaluation
## mean sqaure error
mse <- lbann.model$model %>% keras::evaluate(test_x, test_y) # mse = 0.07
mse
####################################  quantitative evaluation
## mean sqaure error
mse <- lbann.model$model %>% keras::evaluate(test_x, test_y) # mse = 0.07
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x)
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]})
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm.sum <- data.frame(LBANN = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/tab5_1_summary_prediction.csv")
eval <- cvms::evaluate(
data = data.frame(predict = as.character(y_pred.lbann), true = as.character(test$y)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/tab5a_confusion_matrix_lbann.png")
plot_confusion_matrix(eval)
dev.off()
######################################################################################
############# LBA Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(lba)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv")
test <- read.csv("Data/testdata_1.csv")
test_x <- evm.test(y ~ P, newdata = test, trainingset = train)
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train)
#################################### LBA
set.seed(1)
contable <- table(train$P, train$y)
write.csv(contable, "Output/tab3_contingency_table_example1.csv")
lba.model <- lba(y ~ P, data = train, K = 3, method = "mle", trace.lba = F)
#################################### qualitative evaluation
lba.model
#################################### qualitative evaluation
as.matrix(lba.model)
#################################### qualitative evaluation
lba.model$A
#################################### qualitative evaluation
write.csv(round(lba.model$A,2), "Output/tab4_1_mixing parameters A.csv")
write.csv(round(lba.model$B, 2), "Output/tab4_2_latent budgets B.csv")
####################################  quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B)
## loss
mse <- mean((test_y - y_pred.lba)^2) # 0.11
ms
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- as.numeric(apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]}))
confusionMatrix(as.factor(y_pred.lba), reference = as.factor(test$y)) # 0.64
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- as.numeric(apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]}))
####################################  quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B)
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- as.numeric(apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]}))
confusionMatrix(as.factor(y_pred.lba), reference = as.factor(test$y)) # 0.64
cm <- confusionMatrix(as.factor(y_pred.lba), reference = as.factor(test$y)) # 0.64
####################################  quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B)
## mean sqaure error
mse <- mean((test_y - y_pred.lba)^2) # mse = 0.11
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- as.numeric(apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]}))
cm <- confusionMatrix(as.factor(y_pred.lba), reference = as.factor(test$y)) # 0.64
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm.sum <- data.frame(LBANN = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
cm.sum
cm.sum <- data.frame(LBA = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/tab5_2_summary_prediction.csv")
# draw the confusion matrix
eval <- evaluate(
data = data.frame(predict = as.character(y_pred.lba), true = as.character(test$y)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/fig5b_confusion_matrix_lba.png")
plot_confusion_matrix(eval)
dev.off()
write.csv(cm.sum, "Output/tab5_2_summary_prediction_lba.csv")
######################################################################################
############# LBA-NN Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv")
test <- read.csv("Data/testdata_1.csv")
test_x <- evm.test(y ~ P, newdata = test, trainingset = train)
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train)
#################################### Set LBA-NN
# build the model
set_random_seed(10)
lbann.model <- lbann(y ~ P, data = train, num.neurons = 8, epochs = 50,
activation.1 = "relu", activation.2 = "softmax",
val_split.ratio = 0, lr = 0.01, K =3)
#################################### qualitative evaluation
# Importance plot
lbann.model$importance.plot
ggsave("Output/fig3_importance_plot_example_1.png")
# LBA-NN-K-means
lbann.model$biplot
ggsave("Output/fig4_biplot_example_1.png")
####################################  quantitative evaluation
## mean sqaure error
mse <- lbann.model$model %>% keras::evaluate(test_x, test_y) # mse = 0.07
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x)
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]})
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm.sum <- data.frame(LBANN = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/tab5_1_summary_prediction_lbann.csv")
# draw the confusion matrix
eval <- cvms::evaluate(
data = data.frame(predict = as.character(y_pred.lbann), true = as.character(test$y)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/fig5a_confusion_matrix_lbann.png")
plot_confusion_matrix(eval)
dev.off()
######################################################################################
############# LBA Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(lba)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv")
test <- read.csv("Data/testdata_1.csv")
test_x <- evm.test(y ~ P, newdata = test, trainingset = train)
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train)
#################################### LBA
set.seed(1)
contable <- table(train$P, train$y)
write.csv(contable, "Output/tab3_contingency_table_example1.csv")
lba.model <- lba(y ~ P, data = train, K = 3, method = "mle", trace.lba = F)
#################################### qualitative evaluation
write.csv(round(lba.model$A, 2), "Output/tab4_1_mixing parameters A.csv")
write.csv(round(lba.model$B, 2), "Output/tab4_2_latent budgets B.csv")
####################################  quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B)
## mean sqaure error
mse <- mean((test_y - y_pred.lba)^2) # mse = 0.11
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- as.numeric(apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]}))
cm <- confusionMatrix(as.factor(y_pred.lba), reference = as.factor(test$y)) # 0.64
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1")
cm <- as.matrix(cm, what = "classes")[var,]
cm.sum <- data.frame(LBA = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/tab5_2_summary_prediction_lba.csv")
# draw the confusion matrix
eval <- evaluate(
data = data.frame(predict = as.character(y_pred.lba), true = as.character(test$y)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/fig5b_confusion_matrix_lba.png")
plot_confusion_matrix(eval)
dev.off()
data <- read.csv("Data/data_1.csv")
contable <- table(data$P, data$y)
write.csv(contable, "Output/tab3_contingency_table_example1.csv") # table 3: contingency table of the data
contable
######################################################################################
############# LBA-NN Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv") # training
test <- read.csv("Data/testdata_1.csv") # test
test_x <- evm.test(y ~ P, newdata = test, trainingset = train) # input data matrix for the test set
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train) # output data matrix for the test set
#################################### Set LBA-NN
# build the model
set_random_seed(10)  # seed
lbann.model <- lbann(y ~ P, data = train, num.neurons = 8, epochs = 50,
activation.1 = "relu", activation.2 = "softmax",
val_split.ratio = 0, lr = 0.01, K =3)
#################################### quantitative evaluation
## mean sqaure error
mse <- lbann.model$model %>% keras::evaluate(test_x, test_y) # mse = 0.07
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x) # predicted Y
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]}) # predicted class
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$y)) # summary: accuracy = 0.75
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1") # all indicators
cm <- as.matrix(cm, what = "classes")[var,] # extract used indicators
cm.sum <- data.frame(LBANN = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
cm
cm.sum
######################################################################################
############# LBA-NN Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_1.csv") # training
test <- read.csv("Data/testdata_1.csv") # test
test_x <- evm.test(y ~ P, newdata = test, trainingset = train) # input data matrix for the test set
test_y <- rvm.test(y ~ P, newdata = test, trainingset = train) # output data matrix for the test set
#################################### Set LBA-NN
# build the model
set_random_seed(10)  # seed
lbann.model <- lbann(y ~ P, data = train, num.neurons = 8, epochs = 50,
activation.1 = "relu", activation.2 = "softmax",
val_split.ratio = 0, lr = 0.01, K =3)
