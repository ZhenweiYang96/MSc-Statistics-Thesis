rm(list=ls())
library(lbann)
source("functions.R")
library(tensorflow)
library(keras)
library(tidyverse)
library(lba)
library(caret)
library(cvms)

######################################################################################
############# linear data - two variables
######################################################################################
# load data
train <- read.csv("Previous dataset/train.csv") 
#train <- train %>% filter(cause.of.death != "asolliq" & cause.of.death != "dhss")
test <- read.csv("Previous dataset/test.csv")
#test <- test %>% filter(cause.of.death != "asolliq" & cause.of.death != "dhss")

test_x <- evm.test(cause.of.death ~ gender + age, 
                   newdata = test, trainingset = train, interaction = F)
test_y <- rvm.test(cause.of.death ~ gender + age,
                   newdata = test, trainingset = train)

#################################### LBANN
# hyperparameter tuning
runs <- run_tuning(cause.of.death ~ gender + age, data = train, 
                   interaction = F, directory = "hyperparameter tunning/suicide", 
                   units = 2^seq(4,6),
                   lr = c(0.01,0.001,0.0001))
saveRDS(runs, "hyperparameter tunning/suicide.rds")
runs[which.max(runs$metric_val_accuracy),]

# build the LBANN model
set_random_seed(123)# 123
lbann.model <- lbann(cause.of.death ~ gender + age, 
                       data = train, num.neurons = 32, epochs = 50,
                       activation.1 = "relu", activation.2 = "softmax",
                       lr = 0.0001,
                       val_split.ratio = 0, K = 3)

### qualitative evaluation
# importance plots
lbann.model$importance.plot
ggsave("Output/S1_importance_plot_example_3.png")

# biplots
lbann.model$biplot
ggsave("Output/S2_biplot_example_3.png")

### quantitative evaluation
## loss 
lbann.model$model %>% keras::evaluate(test_x, test_y)


## acc + pre + recall
y_pred.lbann <- predict(lbann.model$model, x = test_x)
colnames(y_pred.lbann) <- colnames(lbann.model$output.matrix)
#multiclass.roc(test$cause.of.death, y_pred.lbann)
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]})


confusionMatrix(as.factor(y_pred.lbann), reference = as.factor(test$cause.of.death)) 

eval <- cvms::evaluate(
  data = data.frame(predict = as.character(y_pred.lbann), true = as.character(test$cause.of.death)),
  target_col = "true",
  prediction_cols = "predict",
  type = "multinomial"
)
png("Output/S3a_confusion_matrix_lbann.png")
plot_confusion_matrix(eval)
dev.off()

# # K means
# import <- lbann$importance
# set.seed(1)
# pc <- prcomp(t(import), center = T, scale. = T)
# PCbiplot(pc, cluster = kmeans(t(lbann$importance), centers = 3)$cluster)
# # prcomp(t(import), center = T, scale. = T)$x %>%
# #   as_tibble() %>% 
# #   mutate(rowname = colnames(import)) %>% 
# #   bind_cols(cluster = as.factor(kmeans(t(lbann$importance), centers = 3)$cluster)) %>% 
# #   ggplot(aes(x = PC1, y = PC2, color = cluster, label = rowname )) +
# #   geom_point() + 
# #   geom_text(hjust=0.5, vjust=1.2) +
# #   scale_color_discrete()
# # kmeans(t(lbann$importance), centers = 3)$cluster

#################################### LBA
set.seed(1)

lba.model <- lba(cause.of.death ~ gender + age, data = train, K = 3, method = "ls", trace.lba = F)
#summary(goodnessfit(lba.model))

### quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B)
colnames(y_pred.lba) <- colnames(lbann.model$output.matrix)

## loss 
mean((test_y - y_pred.lba)^2) # 0.09257

## acc + pre + recall
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]})
confusionMatrix(as.factor(y_pred.lba), reference = as.factor(test$cause.of.death)) # 0.63

eval <- cvms::evaluate(
  data = data.frame(predict = as.character(y_pred.lba), true = as.character(test$cause.of.death)),
  target_col = "true",
  prediction_cols = "predict",
  type = "multinomial"
)
png("Output/S3b_confusion_matrix_lba.png")
plot_confusion_matrix(eval)
dev.off()

# LBA
lba.model
