######################################################################
########### dataset 1 in "constrained latent budget analysis
######################################################################
rm(list=ls()) # clear all
library(tidyverse) # load packages
######################################################################
# the function is used to convert the frequencies in the table to
# cases in rows
countsToCases <- function(x, countcol = "Freq") {
# Get the row indices to pull from x
idx <- rep.int(seq_len(nrow(x)), x[[countcol]])
# Drop count column
x[[countcol]] <- NULL
# Get the rows from x
x[idx, ]
}
######################################################################
########  male data
table.male <- data.frame(
row.names = c("10-15", "15-20", "20-25", "25-30", "30-35",
"35-40", "40-45", "45-50", "50-55", "55-60",
"60-65", "65-70", "70-75", "75-80", "80-85",
"85-90", "90+"),
asolliq = c(4, 348, 808, 789, 916, 1118,
926, 855, 684, 502, 516, 513,
425, 266, 159, 70, 18),
bgas = c(0, 7, 32, 26, 17, 27,
13, 9, 14, 6, 5, 8,
5, 4, 2, 1, 0),
cothergas = c(0, 67, 229, 243, 257, 313,
250, 203, 136, 77, 74, 31,
21, 9, 2, 0, 1),
dhss = c(247, 578, 699, 648, 825, 1278,
1273, 1381, 1282, 972, 1249, 1360,
1268, 866, 479, 259, 76),
edrown = c(1, 22, 44, 52, 74, 87,
89, 71, 87, 49, 83, 75,
90, 63, 39, 16, 4),
fgunexp = c(17, 179, 316, 268, 291, 293,
299, 347, 229, 151, 162, 164,
121, 78, 18, 10, 2),
gknives = c(1, 11, 35, 38, 52, 49,
53, 68, 62, 46, 52, 56,
44, 30, 18, 9 ,4),
hjump = c(6, 74, 109, 109, 123, 134,
78, 103, 63, 66, 92, 115,
119, 79, 46, 18, 6),
iother = c(9, 175, 289, 226, 281, 268,
198, 190, 146, 77, 122, 95,
82, 34, 19, 10, 2)
)
data.male <- table.male %>%
rownames_to_column() %>%            # set row names as a variable
gather(rowname2,Freq,-rowname)
data.male <- countsToCases(data.male)
data.male$gender <- rep("male", nrow(data.male)) # add indicator: gender
########  female data
table.female <- data.frame(
row.names = c("10-15", "15-20", "20-25", "25-30", "30-35",
"35-40", "40-45", "45-50", "50-55", "55-60",
"60-65", "65-70", "70-75", "75-80", "80-85",
"85-90", "90+"),
asolliq = c(28, 353, 540, 454, 530, 688,
566, 716, 942, 723, 820, 740,
624, 495, 292, 113, 24),
bgas = c(0, 2, 4, 6, 2, 5,
4, 6, 7, 3, 8, 8,
6, 8, 3, 4, 1),
cothergas = c(3, 11, 20, 27, 29, 44,
24, 24, 26, 14, 8, 4,
4, 1, 2, 0, 0),
dhss = c(20, 81, 111, 125, 178, 272,
343, 447, 691, 527, 702, 785,
610, 420, 223, 83, 19),
edrown = c(0, 6, 24, 33, 42, 64,
76, 94, 184, 163, 245, 271,
244, 161, 78, 14, 4),
fgunexp = c(1, 15, 9, 26, 14, 24,
18, 13, 21, 14, 11, 4,
1, 2, 0, 0, 0),
gknives = c(0, 2, 9, 7, 20, 14,
22, 21, 37, 30, 35, 38,
27, 29, 10, 6, 2),
hjump = c(10, 43, 78, 86, 92, 98,
103, 95, 129, 92, 140, 156,
129, 129, 84, 34, 7),
iother = c(6, 47, 67, 75, 78, 110,
86, 88, 131, 92, 114, 90,
46, 35, 23, 2, 0)
)
data.female <- table.female %>%
rownames_to_column() %>%            # set row names as a variable
gather(rowname2,Freq,-rowname)
data.female <- countsToCases(data.female)
data.female$gender <- rep("female", nrow(data.female)) # add indicator: gender
########## full data
data <- rbind(data.male, data.female)
colnames(data) <- c("age", "cause.of.death", "gender")
data <- data %>% dplyr::select(gender, age, cause.of.death)
write_csv(data, "Data/data_3. csv")
######### split the data
set.seed(123)
indices <- sample(1:nrow(data), 10000, replace = F) # indices for test data (10000 obs)
train <- data[-indices, ]
test <- data[indices,]
write.csv(train,"Data/traindata_3.csv", row.names = F)
write.csv(test, "Data/testdata_3.csv", row.names = F)
######################################################################################
############# LBA-NN Implementation on Example 1
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# linear data - one variable
######################################################################################
# load data
train <- read.csv("Data/traindata_3.csv") # training
test <- read.csv("Data/testdata_3.csv") # test
test_x <- evm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # input data matrix for the test set
test_y <- rvm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # output data matrix for the test set
#################################### Set LBA-NN
# build the model
set_random_seed(123)  # seed
lbann.model <- lbann(cause.of.death ~ gender + age,
data = train, num.neurons = 32, epochs = 50,
activation.1 = "relu", activation.2 = "softmax",
lr = 0.0001,
val_split.ratio = 0, K = 3)
#################################### qualitative evaluation
# Importance plot
lbann.model$importance.plot
ggsave("Output/figS1_importance_plot_example_3.png")
# LBA-NN-K-means
lbann.model$biplot
ggsave("Output/figS2_biplot_example_3.png")
#################################### quantitative evaluation
## mean sqaure error
mse <- lbann.model$model %>% keras::evaluate(test_x, test_y) # mse = 0.06
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x) # predicted Y
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]}) # predicted class
cm <- confusionMatrix(table(predict = as.factor(y_pred.lbann), true = as.factor(test$cause.of.death))) # summary: accuracy = 0.75
cm <- confusionMatrix(table(predict = y_pred.lbann, true = as.factor(test$cause.of.death))) # summary: accuracy = 0.75
y_pred.lbann
as.factor(test$cause.of.death)
test$cause.of.death
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$cause.of.death)) # summary: accuracy = 0.75
?confusionMatrix
cm <- caret::confusionMatrix(table(predict = y_pred.lbann, true = test$cause.of.death)) # summary: accuracy = 0.75
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x) # predicted Y
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]}) # predicted class
cm <- confusionMatrix(table(predict = y_pred.lbann, true = test$cause.of.death)) # summary: accuracy = 0.75
confusionMatrix(as.factor(y_pred.lbann), reference = as.factor(test$cause.of.death))
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x) # predicted Y
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]}) # predicted class
cm <- confusionMatrix(as.factor(y_pred.lbann), reference = as.factor(test$cause.of.death))  # summary: accuracy = 0.75
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1") # all indicators
cm <- as.matrix(cm, what = "classes")[var,] # extract used indicators
cm.sum <- data.frame(LBANN = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/tabS4_1_summary_prediction_lbann.csv") # table 5 (LBA part: summary of the performance)
# draw the confusion matrix
eval <- cvms::evaluate(
data = data.frame(predict = as.character(y_pred.lbann), true = as.character(test$cause.of.death)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/figS3a_confusion_matrix_lbann.png")
plot_confusion_matrix(eval)
dev.off()
######################################################################################
############# LBA Implementation on Example 3
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(lba)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# Previous data in "constrained LBA"
######################################################################################
# load data
train <- read.csv("Data/traindata_3.csv") # training
test <- read.csv("Data/testdata_3.csv") # test
data <- read.csv("Data/data_3.csv")
######################################################################
########### dataset 1 in "constrained latent budget analysis
######################################################################
rm(list=ls()) # clear all
library(tidyverse) # load packages
######################################################################
# the function is used to convert the frequencies in the table to
# cases in rows
countsToCases <- function(x, countcol = "Freq") {
# Get the row indices to pull from x
idx <- rep.int(seq_len(nrow(x)), x[[countcol]])
# Drop count column
x[[countcol]] <- NULL
# Get the rows from x
x[idx, ]
}
######################################################################
########  male data
table.male <- data.frame(
row.names = c("10-15", "15-20", "20-25", "25-30", "30-35",
"35-40", "40-45", "45-50", "50-55", "55-60",
"60-65", "65-70", "70-75", "75-80", "80-85",
"85-90", "90+"),
asolliq = c(4, 348, 808, 789, 916, 1118,
926, 855, 684, 502, 516, 513,
425, 266, 159, 70, 18),
bgas = c(0, 7, 32, 26, 17, 27,
13, 9, 14, 6, 5, 8,
5, 4, 2, 1, 0),
cothergas = c(0, 67, 229, 243, 257, 313,
250, 203, 136, 77, 74, 31,
21, 9, 2, 0, 1),
dhss = c(247, 578, 699, 648, 825, 1278,
1273, 1381, 1282, 972, 1249, 1360,
1268, 866, 479, 259, 76),
edrown = c(1, 22, 44, 52, 74, 87,
89, 71, 87, 49, 83, 75,
90, 63, 39, 16, 4),
fgunexp = c(17, 179, 316, 268, 291, 293,
299, 347, 229, 151, 162, 164,
121, 78, 18, 10, 2),
gknives = c(1, 11, 35, 38, 52, 49,
53, 68, 62, 46, 52, 56,
44, 30, 18, 9 ,4),
hjump = c(6, 74, 109, 109, 123, 134,
78, 103, 63, 66, 92, 115,
119, 79, 46, 18, 6),
iother = c(9, 175, 289, 226, 281, 268,
198, 190, 146, 77, 122, 95,
82, 34, 19, 10, 2)
)
data.male <- table.male %>%
rownames_to_column() %>%            # set row names as a variable
gather(rowname2,Freq,-rowname)
data.male <- countsToCases(data.male)
data.male$gender <- rep("male", nrow(data.male)) # add indicator: gender
########  female data
table.female <- data.frame(
row.names = c("10-15", "15-20", "20-25", "25-30", "30-35",
"35-40", "40-45", "45-50", "50-55", "55-60",
"60-65", "65-70", "70-75", "75-80", "80-85",
"85-90", "90+"),
asolliq = c(28, 353, 540, 454, 530, 688,
566, 716, 942, 723, 820, 740,
624, 495, 292, 113, 24),
bgas = c(0, 2, 4, 6, 2, 5,
4, 6, 7, 3, 8, 8,
6, 8, 3, 4, 1),
cothergas = c(3, 11, 20, 27, 29, 44,
24, 24, 26, 14, 8, 4,
4, 1, 2, 0, 0),
dhss = c(20, 81, 111, 125, 178, 272,
343, 447, 691, 527, 702, 785,
610, 420, 223, 83, 19),
edrown = c(0, 6, 24, 33, 42, 64,
76, 94, 184, 163, 245, 271,
244, 161, 78, 14, 4),
fgunexp = c(1, 15, 9, 26, 14, 24,
18, 13, 21, 14, 11, 4,
1, 2, 0, 0, 0),
gknives = c(0, 2, 9, 7, 20, 14,
22, 21, 37, 30, 35, 38,
27, 29, 10, 6, 2),
hjump = c(10, 43, 78, 86, 92, 98,
103, 95, 129, 92, 140, 156,
129, 129, 84, 34, 7),
iother = c(6, 47, 67, 75, 78, 110,
86, 88, 131, 92, 114, 90,
46, 35, 23, 2, 0)
)
data.female <- table.female %>%
rownames_to_column() %>%            # set row names as a variable
gather(rowname2,Freq,-rowname)
data.female <- countsToCases(data.female)
data.female$gender <- rep("female", nrow(data.female)) # add indicator: gender
########## full data
data <- rbind(data.male, data.female)
colnames(data) <- c("age", "cause.of.death", "gender")
data <- data %>% dplyr::select(gender, age, cause.of.death)
data
write_csv(data, "Data/data_3.csv")
######################################################################################
############# LBA Implementation on Example 3
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(lba)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# Previous data in "constrained LBA"
######################################################################################
# load data
train <- read.csv("Data/traindata_3.csv") # training
test <- read.csv("Data/testdata_3.csv") # test
data <- read.csv("Data/data_3.csv")
### contingency table
contable <- rbind(table(data %>% filter(gender == "male") %>% dplyr::select(-gender)),
table(data %>% filter(gender == "female") %>% dplyr::select(-gender)))
contable <- addmargins(cont)
contable <- addmargins(contable)
contable
write.csv(contable, "Output/tabS2_contingency_table_example3.csv") # table 3: contingency table of the data
#################################### LBA
set.seed(1)
lba.model <- lba(cause.of.death ~ gender + age, data = train, K = 3,
method = "ls", trace.lba = F) # build LBA with 3 latent budgets
#################################### qualitative evaluation
write.csv(round(lba.model$A, 2), "Output/tabS3_1_mixing parameters A.csv")
write.csv(round(lba.model$B, 2), "Output/tabS3_2_latent budgets B.csv")
#################################### quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B) # predicted Y
test_x <- evm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # input data matrix for the test set
test_y <- rvm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # output data matrix for the test set
#################################### quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B) # predicted Y
## mean sqaure error
mse <- mean((test_y - y_pred.lba)^2) # mse = 0.23
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- as.numeric(apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]}))  # predicted class
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
#################################### quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B) # predicted Y
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- as.numeric(apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]}))  # predicted class
y_pred.lba
#################################### quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B) # predicted Y
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]})  # predicted class
cm <- confusionMatrix(as.factor(y_pred.lba), reference = as.factor(test$cause.of.death)) # accuracy = 0.64
cm
acc <- as.matrix(cm,what="overall")[1] # acc
var <- c("Pos Pred Value","Recall", "Specificity", "F1") # all indicators
cm <- as.matrix(cm, what = "classes")[var,] # extract used indicators
cm.sum <- data.frame(LBA = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/tabS4_2_summary_prediction_lba.csv") # table 5 (LBA part: summary of the performance)
# draw the confusion matrix
eval <- cvms::evaluate(
data = data.frame(predict = as.character(y_pred.lba), true = as.character(test$cause.of.death)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/figS3b_confusion_matrix_lba.png") # figure 5b
plot_confusion_matrix(eval)
dev.off()
######################################################################################
############# LBA-NN Implementation on Example 3
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
library(tensorflow)
library(lbann)
library(keras)
library(tidyverse)
library(caret)
library(cvms)
######################################################################################
############# Previous data in "constrained LBA"
######################################################################################
# load data
train <- read.csv("Data/traindata_3.csv") # training
test <- read.csv("Data/testdata_3.csv") # test
test_x <- evm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # input data matrix for the test set
test_y <- rvm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # output data matrix for the test set
#################################### Set LBA-NN
# build the model
set_random_seed(123)  # seed
lbann.model <- lbann(cause.of.death ~ gender + age,
data = train, num.neurons = 32, epochs = 50,
activation.1 = "relu", activation.2 = "softmax",
lr = 0.0001,
val_split.ratio = 0, K = 3)
#################################### qualitative evaluation
# Importance plot
lbann.model$importance.plot
ggsave("Output/figS1_importance_plot_example_3.png")
# LBA-NN-K-means
lbann.model$biplot
ggsave("Output/figS2_biplot_example_3.png")
#################################### quantitative evaluation
## mean sqaure error
mse <- lbann.model$model %>% keras::evaluate(test_x, test_y) # mse = 0.08
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
y_pred.lbann <- predict(lbann.model$model, x = test_x) # predicted Y
y_pred.lbann <- apply(y_pred.lbann, 1, function(x) {colnames(lbann.model$output.matrix)[which.max(x)]}) # predicted class
cm <- confusionMatrix(as.factor(y_pred.lbann), reference = as.factor(test$cause.of.death))  # summary: accuracy = 0.43
acc <- as.matrix(cm,what="overall")[1]
var <- c("Pos Pred Value","Recall", "Specificity", "F1") # all indicators
cm <- as.matrix(cm, what = "classes")[var,] # extract used indicators
cm.sum <- data.frame(LBANN = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/tabS4_1_summary_prediction_lbann.csv") # table S4 (LBANN part: summary of the performance)
# draw the confusion matrix
eval <- cvms::evaluate(
data = data.frame(predict = as.character(y_pred.lbann), true = as.character(test$cause.of.death)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/figS3a_confusion_matrix_lbann.png")
plot_confusion_matrix(eval)
dev.off()
######################################################################################
############# LBA Implementation on Example 3
######################################################################################
rm(list=ls())
# Load packages and functions
source("Script/4. function.R")
######################################################################################
############# Previous data in "constrained LBA"
######################################################################################
# load data
train <- read.csv("Data/traindata_3.csv") # training
test <- read.csv("Data/testdata_3.csv") # test
data <- read.csv("Data/data_3.csv")
test_x <- evm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # input data matrix for the test set
test_y <- rvm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # output data matrix for the test set
test_x <- evm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # input data matrix for the test set
test_y <- rvm.test(cause.of.death ~ gender + age,
newdata = test, trainingset = train) # output data matrix for the test set
### contingency table
contable <- rbind(table(data %>% filter(gender == "male") %>% dplyr::select(-gender)),
table(data %>% filter(gender == "female") %>% dplyr::select(-gender)))
contable <- addmargins(contable)
write.csv(contable, "Output/tabS2_contingency_table_example3.csv") # table 3: contingency table of the data
#################################### LBA
set.seed(1)
lba.model <- lba(cause.of.death ~ gender + age, data = train, K = 3,
method = "ls", trace.lba = F) # build LBA with 3 latent budgets
#################################### qualitative evaluation
write.csv(round(lba.model$A, 2), "Output/tabS3_1_mixing parameters A.csv")
write.csv(round(lba.model$B, 2), "Output/tabS3_2_latent budgets B.csv")
#################################### quantitative evaluation
y_pred.lba <- test_x %*% lba.model$A %*% t(lba.model$B) # predicted Y
## mean sqaure error
mse <- mean((test_y - y_pred.lba)^2) # mse = 0.11
mse
## accuracy + precision + recall + specificity + f1-score
# Confusion matrix result
colnames(y_pred.lba) <- row.names(lba.model$B)
y_pred.lba <- apply(y_pred.lba, 1, function(x) {colnames(y_pred.lba)[which.max(x)]})  # predicted class
cm <- confusionMatrix(as.factor(y_pred.lba), reference = as.factor(test$cause.of.death)) # accuracy = 0.43
acc <- as.matrix(cm,what="overall")[1] # acc
var <- c("Pos Pred Value","Recall", "Specificity", "F1") # all indicators
cm <- as.matrix(cm, what = "classes")[var,] # extract used indicators
cm.sum <- data.frame(LBA = round(c(mse[1], acc, apply(cm, 1, mean)),2))
row.names(cm.sum) <- c("mean square error","accuracy", "precision", "recall", "specificity", "f1-score")
write.csv(cm.sum, "Output/tabS4_2_summary_prediction_lba.csv") # table S4 (LBA part: summary of the performance)
# draw the confusion matrix
eval <- cvms::evaluate(
data = data.frame(predict = as.character(y_pred.lba), true = as.character(test$cause.of.death)),
target_col = "true",
prediction_cols = "predict",
type = "multinomial"
)
png("Output/figS3b_confusion_matrix_lba.png") # figure S3b
plot_confusion_matrix(eval)
dev.off()
