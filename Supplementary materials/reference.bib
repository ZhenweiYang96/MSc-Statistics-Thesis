
@article {PG2006,
	author = {Pawlowsky-Glahn, V. and Egozcue, J. J.},
	title = {Compositional data and their analysis: an introduction},
	volume = {264},
	number = {1},
	pages = {1--10},
	year = {2006},
	doi = {10.1144/GSL.SP.2006.264.01.01},
	publisher = {Geological Society of London},
	abstract = {Compositional data are those which contain only relative information. They are parts of some whole. In most cases they are recorded as closed data, i.e. data summing to a constant, such as 100\% {\textemdash} whole-rock geochemical data being classic examples. Compositional data have important and particular properties that preclude the application of standard statistical techniques on such data in raw form. Standard techniques are designed to be used with data that are free to range from - $\infty$ to + $\infty$. Compositional data are always positive and range only from 0 to 100, or any other constant, when given in closed form. If one component increases, others must, perforce, decrease, whether or not there is a genetic link between these components. This means that the results of standard statistical analysis of the relationships between raw components or parts in a compositional dataset are clouded by spurious effects. Although such analyses may give apparently interpretable results, they are, at best, approximations and need to be treated with considerable circumspection. The methods outlined in this volume are based on the premise that it is the relative variation of components which is of interest, rather than absolute variation. Log-ratios of components provide the natural means of studying compositional data. In this contribution the basic terms and operations are introduced using simple numerical examples to illustrate their computation and to familiarize the reader with their use.},
	issn = {0305-8719},
	URL = {https://sp.lyellcollection.org/content/264/1/1},
	eprint = {https://sp.lyellcollection.org/content/264/1/1.full.pdf},
	journal = {Geological Society, London, Special Publications}
}

@Inbook{Aitchison1994,
author={Aitchison, John},
title={Principles of compositional data analysis},
series={Lecture Notes--Monograph Series},
year={1994},
publisher={Institute of Mathematical Statistics},
address={Hayward, CA},
volume={Volume 24},
number={0-940600-35-8},
pages={73-81},
doi={10.1214/lnms/1215463786},
url={https://projecteuclid.org/euclid.lnms/1215463786},
url={https://doi.org/10.1214/lnms/1215463786}
}

@inproceedings{Aitchison2008,
  title={The single principle of compositional data analysis, continuing fallacies, confusionsand misunderstandings and some suggested remedies},
  author={Aitchison, John},
  year={2008}
}

@article{baxter2006,
author = {Baxter, Mike and Freestone, Ian},
year = {2006},
month = {07},
pages = {511 - 531},
title = {Log-ratio compositional data analysis in Archaeometry},
volume = {48},
journal = {Archaeometry},
doi = {10.1111/j.1475-4754.2006.00270.x}
}

@ARTICLE{PG2017,
	AUTHOR={Gloor, Gregory B. and Macklaim, Jean M. and Pawlowsky-Glahn, Vera and Egozcue, Juan J.},    
	TITLE={Microbiome Datasets Are Compositional: And This Is Not Optional},      
	JOURNAL={Frontiers in Microbiology},      
	VOLUME={8},      
	PAGES={2224},     
	YEAR={2017},        
	URL={https://www.frontiersin.org/article/10.3389/fmicb.2017.02224},       
	DOI={10.3389/fmicb.2017.02224},      
	ISSN={1664-302X},   
	ABSTRACT={Datasets collected by high-throughput sequencing (HTS) of 16S rRNA gene amplimers, metagenomes or metatranscriptomes are commonplace and being used to study human disease states, ecological differences between sites, and the built environment. There is increasing awareness that microbiome datasets generated by HTS are compositional because they have an arbitrary total imposed by the instrument. However, many investigators are either unaware of this or assume specific properties of the compositional data. The purpose of this review is to alert investigators to the dangers inherent in ignoring the compositional nature of the data, and point out that HTS datasets derived from microbiome studies can and should be treated as compositions at all stages of analysis. We briefly introduce compositional data, illustrate the pathologies that occur when compositional data are analyzed inappropriately, and finally give guidance and point to resources and examples for the analysis of microbiome datasets using compositional data analysis.}
}

@article{raun2016,
title = {Measuring tourism destinations using mobile tracking data},
journal = {Tourism Management},
volume = {57},
pages = {202-212},
year = {2016},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2016.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0261517716300930},
author = {Janika Raun and Rein Ahas and Margus Tiru},
keywords = {Destination, Mobile positioning, Tracking, Destination management, BIG data, Estonia},
abstract = {We develop a methodology for measuring visitor flows to destinations using space-time tracking data. Based on a review of the literature on this topic we propose that a tourism destination has five dimensions – spatial, temporal, compositional, social and dynamic – that can be measured using space-time tracking data. We analyse three of these dimensions, namely the spatial, temporal and compositional, using the mobile positioning data of foreign visitors in Estonia from 2011 to 2013. Results show that smaller destination areas can be differentiated inside the whole country by the geographical, temporal and compositional parameters of the visits. These findings demonstrate applications of “BIG” data in destination management. A monitoring tool based on this methodology and data is currently being used by the Estonian Tourist Board.}
}

@article{Heijden1992,
	doi = {10.2307/270999},
	url = {https://doi.org/10.2307%2F270999},
	year = 1992,
	publisher = {{JSTOR}},
	volume = {22},
	pages = {279},
	author = {Van der Heijden, P.G.M and Mooijaart, A. and De Leeuw, J.},
	title = {Constrained Latent Budget Analysis},
	journal = {Sociological Methodology}
}

@InProceedings{SM2001,
author="Siciliano, Roberta
and Mooijaart, Ab",
editor="Borra, Simone
and Rocci, Roberto
and Vichi, Maurizio
and Schader, Martin",
title="Unconditional Latent Budget Analysis: a Neural Network Approach",
booktitle="Advances in Classification and Data Analysis",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="127--134",
abstract="The latent budget model is a reduced rank model for the analysis of compositional data. The model can be also understood as a supervised neural network model with weights interpreted as conditional probabilities. Main advantage of this approach is that a classification rule for budget data can be defined for new observed cases. In this paper, a constrained (weighted) least-squares algorithm --- which is alternative to the one already introduced in literature for standard latent budget model --- is proposed for the estimation of the parameters. A distinction is made between conditional latent budget analysis (the standard approach) and unconditional latent budget analysis (the neural network approach).",
isbn="978-3-642-59471-7"
}

@article{devan1988,
author = {De Leeuw, J. and Van der Heijden, P.G.M.},
year = {1988},
month = {01},
pages = {},
title = {The analysis of time-budgets with a latent time-budget model.}
}

@article{goodman1974,
 ISSN = {00029602, 15375390},
 URL = {http://www.jstor.org/stable/2776792},
 abstract = {This article presents methods for analyzing the relationships among a set of qualitative variables when some of these variables are specified manifest (i.e., observed) variables and others are latent (i.e., unobserved or unobservable) variables. We shall show how to estimate the magnitude of the various effects represented in pathdiagram models that include both the manifestand latent variables, and also how to test whether this kind of path-diagram model is congruent with the observed data. These methods can be applied in order to analyze data obtained in various kinds of surveys (including panel studies), and also in order to construct tests and indices for purposes of measurement and prediction. To illustrate their wide applicability and flexibility, we shall use these methods to reanalyze several different sets of data which were analyzed earlier by Coleman (1964), Lazarsfeld (1948, 1970), Goodman (1973a), and others. Except for some related conclusions in Goodman (1973a), the methods introduced herein lead to conclusions that are very different from those presented by the other researchers who had analyzed these data earlier.},
 author = {Leo A. Goodman},
 journal = {American Journal of Sociology},
 number = {5},
 pages = {1179--1259},
 publisher = {University of Chicago Press},
 title = {The Analysis of Systems of Qualitative Variables When Some of the Variables Are Unobservable. Part I-A Modified Latent Structure Approach},
 volume = {79},
 year = {1974}
}

@incollection{vanderark1998,
title = {Chapter 33 - Graphical Display of Latent Budget Analysis and Latent Class Analysis, with Special Reference to Correspondence Analysis},
editor = {Jörg Blasius and Michael Greenacre},
booktitle = {Visualization of Categorical Data},
publisher = {Academic Press},
address = {San Diego},
pages = {489-508},
year = {1998},
isbn = {978-0-12-299045-8},
doi = {https://doi.org/10.1016/B978-012299045-8/50037-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780122990458500371},
author = {Van der Ark, L.A. and Van der Heijden,  P.G.M.},
abstract = {Publisher Summary
This chapter presents a graphic display of the latent budget analysis (LBA) and latent class analysis (LCA), with special reference to the correspondence analysis (CA). The LBA and LCA are methods used for the analysis of contingency tables. The LBA is a technique that can be used best when one explanatory and one response variable is present, and the question of interest is how the expected budgets can be composed of a smaller amount of typical or latent budgets. The LCA can be used best when the relation between two or more discrete response variables is studied. The question of interest is whether the sample can be split up into K latent classes such that the relation among the variables is satisfactorily explained by the classes. On the other hand, the CA visualizes how row profiles can be explained by continuous axes, which can be interpreted as latent traits. The chapter shows the visualization of results for the LBA and LCA and how these visualizations are related to the visualizations of the correspondence analysis (CA). The chapter concludes with a discussion on the latent budget model and latent class model.}
}

@misc{nwankpa2018,
      title={Activation Functions: Comparison of trends in Practice and Research for Deep Learning}, 
      author={Chigozie Nwankpa and Winifred Ijomah and Anthony Gachagan and Stephen Marshall},
      year={2018},
      eprint={1811.03378},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@Inbook{Rojas1996,
author="Rojas, Ra{\'u}l",
title="The Backpropagation Algorithm",
bookTitle="Neural Networks: A Systematic Introduction",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="149--182",
abstract="We saw in the last chapter that multilayered networks are capable of computing a wider range of Boolean functions than networks with a single layer of computing units. However the computational effort needed for finding the correct combination of weights increases substantially when more parameters and more complicated topologies are considered. In this chapter we discuss a popular learning method capable of handling such large learning problems---the backpropagation algorithm. This numerical method was used by different research communities in different contexts, was discovered and rediscovered, until in 1985 it found its way into connectionist AI mainly through the work of the PDP group [382]. It has been one of the most studied and used algorithms for neural networks learning ever since.",
isbn="978-3-642-61068-4",
doi="10.1007/978-3-642-61068-4_7",
url="https://doi.org/10.1007/978-3-642-61068-4_7"
}

@article{allen1972,
author = { David M.   Allen },
title = {Mean Square Error of Prediction as a Criterion for Selecting Variables},
journal = {Technometrics},
volume = {13},
number = {3},
pages = {469-475},
year  = {1971},
publisher = {Taylor & Francis},
doi = {10.1080/00401706.1971.10488811},

URL = { 
        https://www.tandfonline.com/doi/abs/10.1080/00401706.1971.10488811
    
},
eprint = { 
        https://www.tandfonline.com/doi/pdf/10.1080/00401706.1971.10488811
    
}

}

@misc{hui2021,
      title={Evaluation of Neural Architectures Trained with Square Loss vs Cross-Entropy in Classification Tasks}, 
      author={Like Hui and Mikhail Belkin},
      year={2021},
      eprint={2006.07322},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@Manual{keras,    title = {keras: R Interface to 'Keras'},    author = {JJ Allaire and François Chollet},    year = {2020},    note = {R package version 2.3.0.0},    url = {https://CRAN.R-project.org/package=keras},  }

@Book{ggplot2,    author = {Hadley Wickham},    title = {ggplot2: Elegant Graphics for Data Analysis},    publisher = {Springer-Verlag New York},    year = {2016},    isbn = {978-3-319-24277-4},    url = {https://ggplot2.tidyverse.org},  }

@Manual{magrittr,    title = {magrittr: A Forward-Pipe Operator for R},    author = {Stefan Milton Bache and Hadley Wickham},    year = {2020},    note = {R package version 2.0.1},    url = {https://CRAN.R-project.org/package=magrittr},  }

@Manual{tensorflow,    title = {tensorflow: R Interface to 'TensorFlow'},    author = {JJ Allaire and Yuan Tang},    year = {2020},    note = {R package version 2.2.0.9000},    url = {https://github.com/rstudio/tensorflow},  }

@INPROCEEDINGS{yang1994,
  author={Yi Yang and Yizong Cheng and Renhong Zhao and Govind, R.},
  booktitle={Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN'94)}, 
  title={Process optimization using neural networks}, 
  year={1994},
  volume={7},
  number={},
  pages={4635-4639 vol.7},
  doi={10.1109/ICNN.1994.375023}}
  
  @Manual{tfruns,    title = {tfruns: Training Run Tools for 'TensorFlow'},    author = {JJ Allaire},    year = {2018},    note = {R package version 1.4},    url = {https://CRAN.R-project.org/package=tfruns},  }
  
  @Manual{lba2018,    title = {lba: Latent Budget Analysis for Compositional Data},    author = {Enio G. Jelihovschi and Ivan Bezerra Allaman},    year = {2018},    note = {R package version 2.4.4},    url = {https://CRAN.R-project.org/package=lba},  }
  
  @article{zhang2018,
  title={Opening the black box of neural networks: methods for interpreting neural network models in clinical applications.},
  author={Z. Zhang and M. Beck and Dave Winkler and B. Huang and W. Sibanda and H. Goyal},
  journal={Annals of translational medicine},
  year={2018},
  volume={6 11},
  pages={
          216
        }
}

@article{olden2002,
title = {Illuminating the “black box”: a randomization approach for understanding variable contributions in artificial neural networks},
journal = {Ecological Modelling},
volume = {154},
number = {1},
pages = {135-150},
year = {2002},
issn = {0304-3800},
doi = {https://doi.org/10.1016/S0304-3800(02)00064-9},
url = {https://www.sciencedirect.com/science/article/pii/S0304380002000649},
author = {Julian D Olden and Donald A Jackson},
keywords = {Connection weights, Sensitivity analysis, Neural Interpretation Diagram, Garson's algorithm, Statistical models},
abstract = {With the growth of statistical modeling in the ecological sciences, researchers are using more complex methods, such as artificial neural networks (ANNs), to address problems associated with pattern recognition and prediction. Although in many studies ANNs have been shown to exhibit superior predictive power compared to traditional approaches, they have also been labeled a “black box” because they provide little explanatory insight into the relative influence of the independent variables in the prediction process. This lack of explanatory power is a major concern to ecologists since the interpretation of statistical models is desirable for gaining knowledge of the causal relationships driving ecological phenomena. In this study, we describe a number of methods for understanding the mechanics of ANNs (e.g. Neural Interpretation Diagram, Garson's algorithm, sensitivity analysis). Next, we propose and demonstrate a randomization approach for statistically assessing the importance of axon connection weights and the contribution of input variables in the neural network. This approach provides researchers with the ability to eliminate null-connections between neurons whose weights do not significantly influence the network output (i.e. predicted response variable), thus facilitating the interpretation of individual and interacting contributions of the input variables in the network. Furthermore, the randomization approach can identify variables that significantly contribute to network predictions, thereby providing a variable selection method for ANNs. We show that by extending randomization approaches to ANNs, the “black box” mechanics of ANNs can be greatly illuminated. Thus, by coupling this new explanatory power of neural networks with its strong predictive abilities, ANNs promise to be a valuable quantitative tool to evaluate, understand, and predict ecological phenomena.}
}

@article{olden2004,
title = {An accurate comparison of methods for quantifying variable importance in artificial neural networks using simulated data},
journal = {Ecological Modelling},
volume = {178},
number = {3},
pages = {389-397},
year = {2004},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2004.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0304380004001565},
author = {Julian D Olden and Michael K Joy and Russell G Death},
keywords = {Statistical models, Explanatory power, Connection weights, Garson’s algorithm, Sensitivity analysis},
abstract = {Artificial neural networks (ANNs) are receiving greater attention in the ecological sciences as a powerful statistical modeling technique; however, they have also been labeled a “black box” because they are believed to provide little explanatory insight into the contributions of the independent variables in the prediction process. A recent paper published in Ecological Modelling [Review and comparison of methods to study the contribution of variables in artificial neural network models, Ecol. Model. 160 (2003) 249–264] addressed this concern by providing a comprehensive comparison of eight different methodologies for estimating variable importance in neural networks that are commonly used in ecology. Unfortunately, comparisons of the different methodologies were based on an empirical dataset, which precludes the ability to establish generalizations regarding the true accuracy and precision of the different approaches because the true importance of the variables is unknown. Here, we provide a more appropriate comparison of the different methodologies by using Monte Carlo simulations with data exhibiting defined (and consequently known) numeric relationships. Our results show that a Connection Weight Approach that uses raw input-hidden and hidden-output connection weights in the neural network provides the best methodology for accurately quantifying variable importance and should be favored over the other approaches commonly used in the ecological literature. Average similarity between true and estimated ranked variable importance using this approach was 0.92, whereas, similarity coefficients ranged between 0.28 and 0.74 for the other approaches. Furthermore, the Connection Weight Approach was the only method that consistently identified the correct ranked importance of all predictor variables, whereas, the other methods either only identified the first few important variables in the network or no variables at all. The most notably result was that Garson’s Algorithm was the poorest performing approach, yet is the most commonly used in the ecological literature. In conclusion, this study provides a robust comparison of different methodologies for assessing variable importance in neural networks that can be generalized to other data and from which valid recommendations can be made for future studies.}
}

@article{hartigan1979,
 ISSN = {00359254, 14679876},
 URL = {http://www.jstor.org/stable/2346830},
 author = {J. A. Hartigan and M. A. Wong},
 journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
 number = {1},
 pages = {100--108},
 publisher = {[Wiley, Royal Statistical Society]},
 title = {Algorithm AS 136: A K-Means Clustering Algorithm},
 volume = {28},
 year = {1979}
}

@article{gabriel1971,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2334381},
 abstract = {Any matrix of rank two can be displayed as a biplot which consists of a vector for each row and a vector for each column, chosen so that any element of the matrix is exactly the inner product of the vectors corresponding to its row and to its column. If a matrix is of higher rank, one may display it approximately by a biplot of a matrix of rank two which approximates the original matrix. The biplot provides a useful tool of data analysis and allows the visual appraisal of the structure of large data matrices. It is especially revealing in principal component analysis, where the biplot can show inter-unit distances and indicate clustering of units as well as display variances and correlations of the variables.},
 author = {K. R. Gabriel},
 journal = {Biometrika},
 number = {3},
 pages = {453--467},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {The Biplot Graphic Display of Matrices with Application to Principal Component Analysis},
 volume = {58},
 year = {1971}
}

@article{lever2016,
title = "Points of Significance: Classification evaluation",
author = "Jake Lever and Martin Krzywinski and Naomi Altman",
year = "2016",
month = jul,
day = "28",
doi = "10.1038/nmeth.3945",
language = "English (US)",
volume = "13",
pages = "603--604",
journal = "Nature Methods",
issn = "1548-7091",
publisher = "Nature Publishing Group",
number = "8",
}

@misc{Dua2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

